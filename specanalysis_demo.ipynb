{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path  # For some basic file functionality\n",
    "import re  # For regular expessions\n",
    "import numpy as np\n",
    "\n",
    "import audiolabel  # To work with TextGrids\n",
    "import parselmouth  # To incorporate Praat features in this notebook\n",
    "\n",
    "import pandas as pd  # For managing dataframes\n",
    "# import seaborn as sns  # For plotting data\n",
    "import matplotlib.pyplot as plt  # For plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "First we need to define a couple of functions, for actions we're going to take often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_freq_dist\n",
    "\n",
    "This is a function that takes a sound object and a row from a datafarme that contains details from a token.  This row may contain any kind of information, but it must minimally include an ending time (T2).\n",
    "\n",
    "As written, the function calculates the center of gravity, standard deviation, skewness, and kurtosis of the frequency distribution of the sound *during a window of 50ms, right-aligned to the ending time*, and returns a tuple (an unordered list) containing these values.  You can change this to any number of other windows, as we discussed.  I've included a commented out line showing how you change it so that it analyzes the whole window from the beginning of the token to the end of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "#   TOKEN: a row of data from a dataframe containing, minimally, a starting (t1) and ending time (t2)\n",
    "#   PSND: a Parselmouth Sound object\n",
    "# returns\n",
    "#   a tuple containing the center of gravity, SD, skewness, and kurtosis of the frequency distribution of PSND starting from 50ms\n",
    "#     token.t2 and ending at token.t2\n",
    "def get_freq_dist(token, psnd):\n",
    "\n",
    "    # cut out a part of PSND and turn it into a Spectrum object\n",
    "    s = psnd.extract_part(token['burst_time']-0.005, token['burst_time']+0.015).to_spectrum()  # 50ms window\n",
    "#     s = psnd.extract_part(token['t2']-0.05, token['t2']).to_spectrum()  # 50ms window\n",
    "#     s = psnd.extract_part(token['t1'], token['t2']).to_spectrum()  # whole window\n",
    "    \n",
    "    # generate values and return\n",
    "    return [s.get_center_of_gravity(), s.get_standard_deviation(), s.get_skewness(), s.get_kurtosis()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_intensity_values\n",
    "\n",
    "This function is similar to `get_freq_dist`, except that it gets intensity values, and it returns values the same 50ms window as `get_freq_dist` and the 50ms window *following* the end of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "#   TOKEN: a row of data from a dataframe containing, minimally, a starting (t1) and ending time (t2)\n",
    "#   PSND: a Parselmouth Sound object\n",
    "# returns\n",
    "#   a tuple containing the intensity of the burst (from 50ms before end of token) and the following vowel (until 50ms \n",
    "#     after the end of token)\n",
    "def get_intensity_values(token, psnd):\n",
    "\n",
    "    # cut out a part of PSND and find its intensity\n",
    "    db_d = psnd.extract_part(token['burst_time']-0.005, token['burst_time']+0.015).get_intensity()  # 50ms window\n",
    "#     db_d = psnd.extract_part(token['t2']-0.05, token['t2']).get_intensity()  # 50ms window\n",
    "#     db_d = psnd.extract_part(token['t1'], token['t2']).get_intensity()  # whole window\n",
    "    db_v = psnd.extract_part(token['t2']+0.025, token['t2']+0.05).get_intensity()  # do the same for the following 50ms\n",
    "    \n",
    "    # return values\n",
    "    return [db_d, db_v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_burst_df\n",
    "\n",
    "This is a function that takes a sound object and TextGrid, and generates a dataframe containing word and burst information for each valid stimulus item in the TextGrid's `words` tier. \n",
    "The TextGrid should contain at least two tiers, named `words` and `phones`.  Other tiers may exist, and will be ignored.\n",
    "\n",
    "As written, the function turns the TextGrid into a dataframe containing only the /d/s that are word onsets, then applies the frequency distribution function `get_freq_dist` to each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "#   PSND: a Parselmouth Sound object\n",
    "#   TG: a TextGrid object containing the tiers 'words' and 'phones'\n",
    "# returns\n",
    "#   a dataframe version of the TextGrid's 'words' tier with additional measurements: center of gravity, SD, skewness, \n",
    "#     and kurtosis of the frequency distribution of PSND starting from 50ms\n",
    "def make_burst_df(psnd, tg):\n",
    "\n",
    "    # turn the TG into a data frame.  as_df returns a dataframes for each tier, so we'll take the first one, the phone tier \n",
    "    df = tg.as_df()[0]\n",
    "\n",
    "    df['word'] = df.center.apply(lambda x: tg.labels_at(x).word.text)  # populate the word tier\n",
    "    df['word_onset'] = df.t1.apply(lambda x: tg.labels_at(x).word.t1 == x)  # determine if row's phone is the onset of the word\n",
    "    df = df[((df.text=='D') | (df.text=='d')) & (df.word_onset)]  # restrict the dataframe to onset /d/s\n",
    "\n",
    "    df['burst_time'] = df.apply(get_burst_time, args=([psnd]), axis=1)\n",
    "    \n",
    "    df['burstvalues'] = df.apply(get_freq_dist, args=([psnd]), axis=1)  # get and store the burst COG, SD, etc\n",
    "    # save each burst value in its own column\n",
    "    df['cog'] = df.burstvalues.apply(lambda x: x[0])\n",
    "    df['sd'] = df.burstvalues.apply(lambda x: x[1])\n",
    "    df['skew'] = df.burstvalues.apply(lambda x: x[2])\n",
    "    df['kurtosis'] = df.burstvalues.apply(lambda x: x[3])\n",
    "    \n",
    "    df['dbvalues'] = df.apply(get_intensity_values, args=([psnd]), axis=1)  # get and store the intensity values\n",
    "    df['db_d'] = df.dbvalues.apply(lambda x: x[0])\n",
    "    df['db_v'] = df.dbvalues.apply(lambda x: x[1])\n",
    "    \n",
    "    return df[['word','t1','t2','burst_time','cog','sd','skew','kurtosis','db_d','db_v']]  # return the dataframe, but only these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_burst_time\n",
    "\n",
    "This is a function that takes a sound object and a row from the dataframe, and returns an approximate time of the burst within that sound.\n",
    "This time is an absolute timestamp in relation to the whole audiofile, and not within the individual word itself.\n",
    "\n",
    "As written, the function assumes that there is a burst located somewhere between the start and end time as defined by `token`, and does not return a likelihood of there being a burst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "#   TOKEN: a row of data from a dataframe containing, minimally, a starting (t1) and ending time (t2)\n",
    "#   PSND: a Parselmouth Sound object\n",
    "# returns\n",
    "#   the time between t1 and t2 that is most likely to be associated with a stop burst.\n",
    "def get_burst_time(token, psnd):\n",
    "    \n",
    "    # The MFCC analysis requires a snippet of audio that is at least 50ms long, so if t2-t1 is shorter than 50ms, add 25ms to either side\n",
    "    (t1, t2)=(token['t1'], token['t2'])\n",
    "    if t2-t1 < 0.05:\n",
    "        t1 = t1-0.025\n",
    "        t2 = t2+0.025\n",
    "        \n",
    "    mfcc = psnd.extract_part(t1, t2, preserve_times=True).to_mfcc()  # get an MFCC object from t1 to t2\n",
    "    m = np.transpose(mfcc.to_array())  # flip the rows and columns in this matrix\n",
    "\n",
    "    diffs = []  # define an empty array of \"differences\", then populate it\n",
    "    for i in range(len(m)-1):\n",
    "        # as is, this script works best when looking at the very first (lowest frequency) coefficient.  I'm not sure why it works, but \n",
    "        # since it does I'm going to leave it that way.  If you find it isn't working, you can play around a little with the index ([0])\n",
    "        diffs = diffs + [(np.transpose(mfcc.to_array())[i+1]-np.transpose(mfcc.to_array())[i])[0]]\n",
    "    \n",
    "    return mfcc.frame_number_to_time(np.argmax(np.abs(diffs))+2)  # turn the frame number back into a timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script assumes that the following data structure, where each subject has their own folder containing their recording and both English and Spanish aligned TextGrids:\n",
    "```\n",
    "./\n",
    "./S01\n",
    "./S01/S01_words.wav\n",
    "./S01/S01_English_aligned.TextGrid\n",
    "./S01/S01_Spanish_aligned.TextGrid\n",
    "./S02\n",
    "./S02/S02_words.wav\n",
    "./S02/S02_English_aligned.TextGrid\n",
    "./S02/S02_Spanish_aligned.TextGrid\n",
    "./etc...\n",
    "```\n",
    "You can include other files in each subject's folder as you wish, and the script will just ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '.'  # Where's the data?  For now, set to current working directory, but can be changed.\n",
    "subjects = [f for f in os.listdir(datadir) if re.match('S\\d\\d',f)]  # get the list of subjects, using regex to match\n",
    "subjects  # check the list of subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what subjects there are, we should be able to predict the names of the audio and annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiosuffix = '_words.wav'\n",
    "engtgsuffix = '_words_English_aligned.TextGrid'\n",
    "spatgsuffix = '_words_Spanish_aligned.TextGrid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok!  Now we're ready to process the data!  We'll iterate through each subject, and send each pair of audio+textgrid to `make_burst_df` for processing, then combine the resulting data into a master single dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the master dataframe\n",
    "df = pd.DataFrame(columns=['speaker','language','word','t1','t2','cog','sd','skew','kurtosis','db_d','db_v'])\n",
    "\n",
    "for s in subjects:  # iterate through the subjects\n",
    "    \n",
    "    # set up paths to the audio files and annotation textgrids\n",
    "    wav_file = os.path.join(datadir,s,s+audiosuffix)\n",
    "    tg_eng_file = os.path.join(datadir,s,s+engtgsuffix)\n",
    "    tg_spa_file = os.path.join(datadir,s,s+spatgsuffix)\n",
    "\n",
    "    # read the audiofile as a Parselmouth Sound object, and the annotations as labelmanagers\n",
    "    psnd = parselmouth.Sound(wav_file)\n",
    "    psnd = pcall(psnd, 'Filter (stop Hann band)...', 0, 300, 100)\n",
    "    tg_eng = audiolabel.LabelManager(from_file=tg_eng_file,from_type='praat')\n",
    "    tg_spa = audiolabel.LabelManager(from_file=tg_spa_file,from_type='praat')\n",
    "\n",
    "    edf = make_burst_df(psnd, tg_eng)  # make a dataframe from the English words\n",
    "    edf['language'] = 'English'  # add a language column and set it to 'English'\n",
    "    edf['speaker'] = s  # add a column for speaker number\n",
    "    sdf = make_burst_df(psnd, tg_spa)  # do the same thing for Spanish\n",
    "    sdf['language'] = 'Spanish'\n",
    "    sdf['speaker'] = s\n",
    "    \n",
    "    # join the two dataframes with the master dataframe, and add speaker as a column\n",
    "    df = df.append(edf, sort=False)\n",
    "    df = df.append(sdf, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a sneak peek at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the intensity columns to calculate two different versions of relative intensity.  By saving both columns, we can compare them and make a choice later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['db_ratio']=df.db_d/df.db_v  # greater than 1 means the burst is louder than the vowel, and higher values are louder bursts\n",
    "df['db_diff']=df.db_d-df.db_v  # positive means the burst is louder than the vowel, and higher values are louder bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./datafiles.csv')  # write this data to a csv file so we can export it to another program (like R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make some plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "f, axes = plt.subplots(2, 3, figsize=(20, 10))  # set up an empty plot with 2x3 subplots\n",
    "sns.boxplot(data=df, x='speaker', y='cog', hue='language', ax=axes[0,0])\n",
    "sns.boxplot(data=df, x='speaker', y='sd', hue='language', ax=axes[0,1])\n",
    "sns.boxplot(data=df, x='speaker', y='skew', hue='language', ax=axes[0,2])\n",
    "sns.boxplot(data=df, x='speaker', y='kurtosis', hue='language', ax=axes[1,0])\n",
    "sns.boxplot(data=df, x='speaker', y='db_diff', hue='language', ax=axes[1,1])\n",
    "sns.boxplot(data=df, x='speaker', y='db_ratio', hue='language', ax=axes[1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
